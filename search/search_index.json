{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"getting-started/changelog/","title":"Changelog","text":""},{"location":"getting-started/changelog/#051","title":"0.5.1","text":"<ul> <li>Fix incorrect prompt template value replacement</li> </ul>"},{"location":"getting-started/changelog/#050","title":"0.5.0","text":"<ul> <li>Extracted common data structures to contracts for interoperability</li> <li>Reorganised namespaces</li> <li>Added VectorStore component</li> <li>Added Retriever component</li> <li>Added LanguageModelChain factory and initial blueprints</li> <li>Added ConcatenateDocuments Chain</li> <li>Added DocumentsRetrieverChain</li> <li>Added CsvFileLoader</li> </ul>"},{"location":"getting-started/changelog/#040","title":"0.4.0","text":"<ul> <li>Added Compare component</li> </ul>"},{"location":"getting-started/changelog/#031","title":"0.3.1","text":"<ul> <li>Cleaned up library dependencies</li> </ul>"},{"location":"getting-started/changelog/#030","title":"0.3.0","text":"<ul> <li>Lots of coding style fixes</li> <li>Renamed Vexo\\Model to Vexo\\LanguageModel</li> <li>Made FinishedGeneratingCompletion event have the whole response instead of just completions</li> <li>Added Vexo\\LanguageModel\\BaseLanguageModel to implement custom models</li> <li>Removed unneeded Vexo\\LanguageModel\\Parameters class</li> <li>Added first version of embeddings</li> <li>Added Tokenizer abstraction</li> <li>Simplified TextSplitters</li> <li>Added TokenTextSplitter that can split text by tokens</li> </ul>"},{"location":"getting-started/changelog/#020","title":"0.2.0","text":"<ul> <li>FakeLanguageModel now also implements EventDispatcherAware for interoperability</li> <li>RegexOutputParser now has default prompt instructions</li> <li>Chain\\Input and Chain\\Output are now complete collection classes</li> <li>Added ability for WebTextChain to auto discover HTTP client</li> <li>Allow for injection of a custom TextExtractor in WebTextChain</li> <li>Added ability to override the default generated cache key prefix to CachingChain</li> </ul>"},{"location":"getting-started/changelog/#010","title":"0.1.0","text":"<ul> <li>Initial release.</li> </ul>"},{"location":"getting-started/contributing/","title":"Contributing","text":"<p>Contributions are very much appreciated! There are several ways you can help with the project.</p>"},{"location":"getting-started/contributing/#coding-guidelines","title":"Coding Guidelines","text":"<ul> <li>Vexo is meant to be lean and focussed and therefore not all feature requests will be accepted.</li> <li>Compatibility breaks or major changes should first be proposed in a GitHub issue outlining why the change is needed, what the benefits are, and what alternatives have been considered.</li> <li>Vexo has minimum PHP version requirement of PHP 8.1. Pull requests must not require a higher version.</li> <li>All code contributions must be accompanied by unit tests to ensure the change works as expected.</li> <li>All code contributions should pass coding style requirements enforced by PHPStan and PHP-CS-Fixer.</li> </ul>"},{"location":"getting-started/contributing/#running-the-tests","title":"Running the tests","text":"<ol> <li> <p>Clone the repository: <pre><code>git clone git@github.com:VexoAI/vexo.git &amp;&amp; cd vexo\n</code></pre></p> </li> <li> <p>Install dependencies using Composer: <pre><code>composer install\n</code></pre></p> </li> <li> <p>Run the tests <pre><code>./run-tests.sh\n</code></pre></p> </li> </ol>"},{"location":"getting-started/contributing/#contribution-documentation","title":"Contribution documentation","text":"<p>Vexo's documentation is maintained in a seperate repository. If you notice any mistakes or would like to expand our documentation with more information, feel free to create an issue there or submit a pull request.</p>"},{"location":"getting-started/contributing/#where-can-i-go-for-help","title":"Where can I go for help?","text":"<p>If you need help, feel free to create an issue with your question and we'll help you as best we can.</p> <p>Thank you for considering contributing to the project!</p>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<p>Vexo requires at least PHP 8.1. Some of the components require additional PHP extensions and tooling to function. See the individual component documentation for more info.</p>"},{"location":"getting-started/installation/#installation_1","title":"Installation","text":"<p>The recommended way to install Vexo is through Composer.</p> <pre><code>composer require vexo/vexo\n</code></pre> <p>When you want to make use of individual components, you have to install them separately. Please check the individual component documentation for the package name and further installation instructions.</p> <p>Notice</p> <p>Currently all of Vexo is contained in a single package. The command above will pull in all the components and their dependencies. In the future this will be split up in multiple component packages so you are able to only pull in what you need.</p>"},{"location":"getting-started/introduction/","title":"What is Vexo?","text":"<p>Vexo is a component library for PHP to help you develop AI-driven applications quickly.</p> <p>It is heavily inspired by LangChain and builds on many of the same concepts.</p> <p>The goals of the project are as follows:</p> <ul> <li>Create a complete collection of components focused on AI-driven applications</li> <li>Prioritize ease of use and simplicity</li> <li>Easy to extend and adapt</li> <li>Leverage the existing PHP ecosystem</li> <li>Connect to a wide range of models, data sources, and tooling</li> </ul>"},{"location":"getting-started/license/","title":"License","text":"<p>Vexo is released under the MIT license.</p> <pre><code>Copyright (c) 2023 Frank van den Brink\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is furnished\nto do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n</code></pre>"},{"location":"getting-started/security-policy/","title":"Security policy","text":"<p>We want to make sure that Vexo is a secure library for all. If you have discovered a security vulnerability in Vexo, we appreciate your help in disclosing it to us in a responsible manner.</p> <p>If you have discovered a vulnerability, please use submit a new security advisory for review. We'll work with you to make sure that we understand the scope of the issue, and that we fully address your concern.</p> <p>After a security issue has been corrected, we'll release a new hotfix as soon as possible.</p>"},{"location":"getting-started/security-policy/#supported-versions","title":"Supported versions","text":"<p>Please see below which issues are still supported for security issues.</p> Version Supported 0.x"},{"location":"reference/introduction/","title":"Components","text":"<p>Warning</p> <p>Vexo is very much still in active development and a lot of components are not available yet or incomplete. The structure is likely to change, and the documentation is incomplete.</p>"},{"location":"reference/advanced/event-handling/","title":"Event Handling","text":"<p>Multiple components in Vexo emit events through an event dispatcher. Classes which support this all implement the <code>Vexo\\Event\\EventDispatcherAware</code> interface. Right now the following components emit events:</p> <ul> <li>Agents</li> <li>Chains</li> <li>Models</li> </ul> <p>By default a Vexo relies on league/event for the default event dispatcher. You can retrieve the event dispatcher by calling the <code>eventDispatcher()</code> method on any supported component.</p> <pre><code>&lt;?php\nuse Vexo\\Chain\\PassthroughChain;\nuse Vexo\\Event\\SomethingHappened;\n$chain = new PassthroughChain();\n$eventDispatcher = $chain-&gt;eventDispatcher(); // Instance of League\\Event\\EventDispatcher\n$eventDispatcher-&gt;subscribeTo(\nSomethingHappened::class,\nfunction (SomethingHappened $event): void {\n// Handle the event\n}\n)\n</code></pre> <p>Look at the documentation for the different components to see which events are emitted. If you would like to subscribe to all events, you can listen for <code>Vexo\\Event\\SomethingHappened</code> on which all events are based.</p>"},{"location":"reference/advanced/event-handling/#override-the-event-dispatcher","title":"Override the Event Dispatcher","text":"<p>You can also provide your own PSR-14 compatible event dispatcher to have the component use that instead.</p> <pre><code>&lt;?php\nuse League\\Event\\EventDispatcher;\n$eventDispatcher = new EventDispatcher();\n$chain-&gt;useEventDispatcher($eventDispatcher);\n</code></pre>"},{"location":"reference/agents/introduction/","title":"Agents","text":"<p>Warning</p> <p>Agents and agent executors are still a bit of a mess. For a look at the current in progress state, there is an example of an MRKL Zero-shot agent in the examples folder.</p>"},{"location":"reference/chains/custom-chains/","title":"Custom Chains","text":"<p>The easiest way to create your own chains is by extending the <code>Vexo\\Chain\\BaseChain</code> class. This will implement the <code>Vexo\\Chain\\Chain</code> and <code>Vexo\\Event\\EventDispatcherAware</code> interfaces out of the box, and will make sure that the standard events are emitted. It will also do basic input validation.</p> <p>You will have to implement the following methods:</p> <ul> <li><code>inputKeys(): array</code>: Returns an array of input keys that your chain requires to be provided. Omit optional keys.</li> <li><code>outputKeys(): array</code>: Returns an array of output keys which your chain will always produce.</li> <li><code>call(Input $input): Output</code>: The actual chain functionality, taking input and producing output.</li> </ul>"},{"location":"reference/chains/custom-chains/#example","title":"Example","text":"<pre><code>&lt;?php\nuse Vexo\\Chain\\BaseChain;\nuse Vexo\\Chain\\Input;\nuse Vexo\\Chain\\Output;\nfinal class AcmeChain extends BaseChain\n{\npublic function inputKeys(): array\n{\nreturn ['question'];\n}\npublic function outputKeys(): array\n{\nreturn ['answer'];\n}\nprotected function call(Input $input): Output\n{\nif ($input-&gt;get('question') == 'What is the meaning of life?') {\nreturn new Output(['answer' =&gt; 42]);\n}\nreturn new Output(['answer' =&gt; 'Dunno.']);\n}\n}\n$chain = new AcmeChain();\n$output = $chain-&gt;process(new Input(['question' =&gt; 'What is the meaning of life?']));\necho $output-&gt;get('answer'); // Outputs: 42\n</code></pre>"},{"location":"reference/chains/custom-chains/#emitting-events","title":"Emitting Events","text":"<p>The <code>BaseChain</code> class will emit the <code>ChainStarted</code> and <code>ChainFinished</code> events on its own. If you would like to additionally emit your own events, you can use the <code>emit</code> method. Make sure your event implements <code>Vexo\\Event\\SomethingHappened</code>.</p> <pre><code>&lt;?php\nprotected function call(Input $input): Output\n{\n// Some code...\n$this-&gt;emit(new AcmeEvent($input, 'Some other info'));\n// More code here...\n}\n</code></pre>"},{"location":"reference/chains/events/","title":"Events","text":"<p>Models will emit the events outlined below. For more info on how to listen for events in Vexo, see Event Handling.</p>"},{"location":"reference/chains/events/#emitted-events","title":"Emitted events","text":""},{"location":"reference/chains/events/#vexochainchainstarted","title":"<code>Vexo\\Chain\\ChainStarted</code>","text":"<p>Emitted just before the chain will start processing, and before input validation.</p> Property Description <code>Vexo\\Chain\\Input $input</code> The input which was provided to the <code>process</code> method."},{"location":"reference/chains/events/#vexochainchainfinished","title":"<code>Vexo\\Chain\\ChainFinished</code>","text":"<p>Emitted after the chain has finished processing, just before returning the output.</p> Property Description <code>Vexo\\Chain\\Input $input</code> The input which was provided to the <code>process</code> method. <code>Vexo\\Chain\\Output $output</code> The output produced by the chain."},{"location":"reference/chains/introduction/","title":"Introduction","text":"<p>Chains are a generic way to combine individual components to enable more complex workflows or use cases that go beyond a single interaction with a model. Sequential chains are the most common which are generally used to have the output from one model or tool feed into the next one while maintaining overall context.</p> <p>In Vexo, each chain implements the <code>Vexo\\Chain\\Chain</code> interface, which defines three methods.</p> Method Description <code>inputKeys(): string[]</code> Returns an array of input variables which the chain accepts. <code>outputKeys(): string[]</code> Returns an array of output variables which the chain produces. <code>process(Input $input): Output</code> Runs the chain. Takes an instance of <code>Input</code> and produces an instance of <code>Output</code>. <p>This generic interface allows us to easily swap out one chain for another if needed, and enables us to easily validate whether the output from one chain can feed into the next.</p>"},{"location":"reference/chains/introduction/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>A chain's process method always takes a single <code>Input</code> object containing all the parameters it needs. You can create one as follows:</p> <pre><code>&lt;?php\n// Assumes $chain is an instance of Vexo\\Chain\\Chain\n$input = new Input(['query' =&gt; 'What is the current weather in Amsterdam?']);\n$output = $chain-&gt;process($input);\n</code></pre> <p>Which keys you use in the array are dependent upon the specific chain you feed this input to. All chains will verify that the input contains all the required variables they need to continue. If it does not, the chain will throw a <code>Vexo\\Chain\\SorryValidationFailed</code> exception.</p> <p>Once the chain has finished processing, it will return an instance of <code>Vexo\\Chain\\Output</code> containing all the output values that the chain has produced. This class implements both PHP's <code>ArrayAccess</code> and <code>IteratorAggregate</code> so you can iterate over the values or access them directly.</p> <pre><code>&lt;?php\n// Get a single value\n$report = $output['report'];\n// Iterate over the output\nforeach ($output as $name =&gt; $value) {\necho \"{$name}: {$value}\\n\";\n}\n</code></pre>"},{"location":"reference/chains/testing-with-chains/","title":"Testing Chains","text":"<p>Vexo provides an implementation of <code>Vexo\\LanguageModel\\Chain</code> which you can use for testing classes that depend on it.</p> <p>This <code>PassthroughChain</code> simply outputs whatever its been given as input.</p> <pre><code>&lt;?php\nuse Vexo\\Chain\\Input;\nuse Vexo\\Chain\\PassthroughChain;\n$chain = new PassthroughChain();\n// Call the chain\n$output = $chain-&gt;process(\nnew Input(['foo' =&gt; 'bar'])\n);\n// Outputs: bar\necho $output['foo'];\n</code></pre> <p>If you want the chain to be explicitly aware of the input and output it processes (and validate accordingly), you can provide the keys in the constructor.</p> <pre><code>&lt;?php\n$chain = new PassthroughChain(\ninputKeys: ['foo'],\noutputKeys: ['foo']\n);\n</code></pre> <p>If you specifiy the input keys and then pass input to the <code>process</code> method that does not contain all of the configured keys, an exception will be thrown.</p>"},{"location":"reference/chains/standard-chains/","title":"Standard Chains","text":"<p>Vexo comes with a few standard chains out of the box.</p> <ul> <li>Language Model Chain: A chain wrapped around a language model.</li> <li>WebText Chain: A chain that can extract text from a website.</li> </ul> <p>Then there are also a few chains which nest other chains to add additional functionality:</p> <ul> <li>Sequential Chain: A chain that nests one or more other chains and ties them together in a sequential pipeline.</li> <li>Caching Chain: A chain that nests another chain to provide it with caching capabilities.</li> </ul> <p>More types of chains are in the works.</p>"},{"location":"reference/chains/standard-chains/caching-chain/","title":"Caching Chain","text":"<p>The chain wraps another chain to provide it with caching capabilities. It relies on being provided a PSR-16 compatible cache implementation.</p> <p>In the example below we wrap it around a WebTextChain to cache webpage text extractions.</p> <pre><code>&lt;?php\nuse Symfony\\Component\\Cache\\Adapter\\ArrayAdapter;\nuse Symfony\\Component\\Cache\\Psr16Cache;\nuse Vexo\\Chain\\CachingChain;\nuse Vexo\\Chain\\Input;\nuse Vexo\\Chain\\WebTextChain;\n$cachingChain = new CachingChain(\nchain: new WebTextChain(),\ncache: new Psr16Cache(new ArrayAdapter())\n);\n$output = $cachingChain-&gt;process(\nnew Input(['url' =&gt; 'https://example.com/'])\n); // Will trigger an HTTP request\n$output = $cachingChain-&gt;process(\nnew Input(['url' =&gt; 'https://example.com/'])\n); // Second call is returned from cache\n</code></pre>"},{"location":"reference/chains/standard-chains/caching-chain/#cache-lifetime","title":"Cache lifetime","text":"<p>By default no lifetime for the cached outputs is specified, which means that the default lifetime set on the injected cache will be used. If you would like CachingChain to use a specific lifetime, you can provide it using the <code>lifetime</code> argument.</p> <pre><code>&lt;?php\n$cachingChain = new CachingChain(\nchain: new WebTextChain(),\ncache: new Psr16Cache(new ArrayAdapter()),\nlifetime: 300 // Cache for 5 minutes\n);\n</code></pre>"},{"location":"reference/chains/standard-chains/caching-chain/#cache-keys","title":"Cache keys","text":"<p>CachingChain bases the cache keys on the class name of the nested chain, and a SHA-256 hash of the input data. In the example above, it would result in using the following cache key:</p> <pre><code>vexo.chain.webtextchain.1fe906a36169711200b28ac6f2c5d4abda77d2d6b58025eb62c1a1de1041a6f9\n</code></pre> <p>This means that in some scenarios, if the cache is shared between multiple CachingChains each wrapping an instance of the same chain, they may return eachother's cache entries if the input is the same.</p> <p>You can override the cache key prefix by providing the <code>cacheKeyPrefix</code> argument.</p> <pre><code>&lt;?php\n$cachingChain = new CachingChain(\nchain: new WebTextChain(),\ncache: new Psr16Cache(new ArrayAdapter()),\ncacheKeyPrefix: 'my.prefix'\n);\n</code></pre> <p>In the example above the cache key used would now be as follows:</p> <pre><code>my.prefix.1fe906a36169711200b28ac6f2c5d4abda77d2d6b58025eb62c1a1de1041a6f9\n</code></pre>"},{"location":"reference/chains/standard-chains/language-model-chain/","title":"Language Model Chain","text":"<p>This chain enables running queries against a given language model using a prompt template.</p> <p>You can use it as follows.</p> <pre><code>&lt;?php\nuse Vexo\\Chain\\Input;\nuse Vexo\\Chain\\LanguageModelChain;\nuse Vexo\\LanguageModel\\FakeLanguageModel;\nuse Vexo\\LanguageModel\\Response;\nuse Vexo\\Prompt\\BasicPromptTemplate;\n// Replace with instance of a real language model\n$languageModel = new FakeLanguageModel(\nResponse::fromString('I would advise you to stay at the airport.'),\n);\n// Create our basic prompt template\n$promptTemplate = new BasicPromptTemplate(\n'You are a travel advisor. Give me an itinerary for a day trip to {{text}}.',\n['text']\n);\n$chain = new LanguageModelChain(\nlanguageModel: $languageModel,\npromptTemplate: $promptTemplate\n);\n// Call the chain\n$output = $chain-&gt;process(\nnew Input(['text' =&gt; 'Amsterdam'])\n);\n// Outputs: I would advise you to stay at the airport.\necho $output['text'];\n</code></pre>"},{"location":"reference/chains/standard-chains/language-model-chain/#customizing-input-and-output","title":"Customizing Input and Output","text":"<p>Sometimes you want to provide more parameters than a single text input, or you would like the output variable to be more appropriately named.</p> <p>You can change the inputs by providing an array of names in the <code>inputKeys</code> constructor argument. You can change the name of the output variable by providing the <code>outputKey</code> argument.</p> <p>This will allow us to use more relevant names in the prompt template as well, input, and output processing as well:</p> <pre><code>&lt;?php\n// Create our basic prompt template\n$promptTemplate = new BasicPromptTemplate(\n'You are a travel advisor. Give me an itinerary for a {{days}}-day trip to {{destination}}.',\n['destination', 'days']\n);\n$chain = new LanguageModelChain(\nlanguageModel: $languageModel,\npromptTemplate: $promptTemplate,\ninputKeys: ['destination', 'days'],\noutputKey: ['advice']\n);\n// Call the chain\n$output = $chain-&gt;process(\nnew Input(['destination' =&gt; 'Amsterdam', 'days' =&gt; 3])\n);\n// Outputs: I would advise you to stay at the airport.\necho $output['advice'];\n</code></pre>"},{"location":"reference/chains/standard-chains/language-model-chain/#stops","title":"Stops","text":"<p>In some scenarios you want the language model to not generate beyond certain stop words. In that case you provide an array of stop token strings in the <code>stops</code> argument.</p> <pre><code>&lt;?php\n$chain = new LanguageModelChain(\nlanguageModel: $languageModel,\npromptTemplate: $promptTemplate,\nstops: ['Observation:']\n);\n</code></pre>"},{"location":"reference/chains/standard-chains/sequential-chain/","title":"Sequential Chain","text":"<p>The sequential chain allows you to connect multiple chains in sequence. This is useful when you, for instance, want to create more complex workflows involving one or more language models.</p> <p>Once you call <code>process()</code> on the sequential chain, it will add the provided input to a collection of \"known values.\" It then cycles through each of the nested chains in sequence. For each chain in the sequence, it calls the process method with all the known values. It then collects the output and adds that to the known values as well, before continuing on to the next chain in the sequence.</p> <p>Once it has cycled through all the chains, it will return the output of the last chain as the final output.</p> <pre><code>flowchart LR\n    input(Input)\n    kv(Known values)\n    output(Output)\n    chain(Chain N)\n\n    subgraph SequentialChain\n        chain--Output--&gt;kv\n        kv--Input--&gt;chain\n    end\n\n    input--&gt;kv--&gt;output</code></pre>"},{"location":"reference/chains/standard-chains/sequential-chain/#input-validation","title":"Input validation","text":"<p>Upon instantiation SequentialChain will check if any of the required inputs of nested chains are provided as outputs by any preceding chains. A <code>Vexo\\Chain\\SorryValidationFailed</code> exception will be thrown if that's not the case. It is important that any required inputs by a nested chain is properly defined, as well as any outputs that are needed by subsequent chains.</p>"},{"location":"reference/chains/standard-chains/sequential-chain/#output-values","title":"Output values","text":"<p>By default SequentialChain will return the output of the last executed chain. You can override this by explictly providing the keys of known values in the <code>outputKeys</code> constructor argument. Alternatively, you can set <code>outputAll</code> to <code>true</code> to simply have it output all known values.</p>"},{"location":"reference/chains/standard-chains/sequential-chain/#example","title":"Example","text":"<p>The example below creates a simple two-step workflow where we have a language model summarize the contents of a webpage.</p> <pre><code>&lt;?php\nuse Vexo\\Chain\\Chains;\nuse Vexo\\Chain\\Input;\nuse Vexo\\Chain\\LanguageModelChain;\nuse Vexo\\Chain\\SequentialChain;\nuse Vexo\\Chain\\WebTextChain;\nuse Vexo\\LanguageModel\\OpenAIChatLanguageModel;\nuse Vexo\\LanguageModel\\Response;\nuse Vexo\\Prompt\\BasicPromptTemplate;\n// Create our WebTextChain which will retrieve the text from a webpage\n$webTextChain = new WebTextChain(\ninputKey: 'url',\noutputKey: 'webpage-contents'\n);\n// Create our LanguageModelChain which will be responsible for creating the summary\n$languageModelChain = new LanguageModelChain(\nlanguageModel: new OpenAIChatLanguageModel(\n\\OpenAI::client(getenv('OPENAI_API_KEY'))-&gt;chat()\n),\npromptTemplate: new BasicPromptTemplate(\n\"Please summarize the following text:\\n\\n{{webpage-contents}}\",\n['webpage-contents']\n),\ninputKeys: ['webpage-contents'],\noutputKey: ['summary']\n);\n// Finally create the sequential chain tying it all together\n$webpageSummarizer = new SequentialChain(\nnew Chains([$webTextChain, $languageModelChain]),\ninputKeys: ['url'],\noutputKeys: ['summary']\n);\n// Call the chain to summarize a webpage\n$output = $webpageSummarizer-&gt;process(\nnew Input(['url' =&gt; 'https://example.com'])\n);\n// Outputs something like: The text describes a domain that can be used in illustrative...\necho $output['summary'];\n</code></pre>"},{"location":"reference/chains/standard-chains/webtext-chain/","title":"WebText Chain","text":"<p>The WebText chain downloads a webpage and extracts plain text from it. This is useful, for instance, when we have a URL which needs to be inspected, and a subsequent language model chain will inspect or summarize the contents.</p> <p>You can use it as follows.</p> <pre><code>&lt;?php\nuse Vexo\\Chain\\Input;\nuse Vexo\\Chain\\WebTextChain;\n$chain = new WebTextChain();\n// Call the chain\n$output = $chain-&gt;process(\nnew Input(['url' =&gt; 'https://example.com'])\n);\n// Outputs something like:\n// Example Domain This domain is for use in illustrative...\necho $output['text'];\n</code></pre>"},{"location":"reference/chains/standard-chains/webtext-chain/#customizing-input-and-output","title":"Customizing Input and Output","text":"<p>You can change the input and output keys that the chain uses by providing them as constructor aguments.</p> <pre><code>&lt;?php\n$chain = new WebTextChain(\ninputKey: 'location',\noutputKey: 'contents'\n);\n</code></pre>"},{"location":"reference/chains/standard-chains/webtext-chain/#changing-the-text-limit","title":"Changing the text limit","text":"<p>By default the chain limits its output to 8000 bytes. You can change that by providing the <code>maxTextLength</code> argument.</p> <pre><code>&lt;?php\n$chain = new WebTextChain(\nmaxTextLength: 4000\n);\n</code></pre>"},{"location":"reference/chains/standard-chains/webtext-chain/#changing-the-http-client","title":"Changing the HTTP Client","text":"<p>WebTextChain uses <code>php-http/discovery</code> to automatically detect and use an available PSR-18 compatible client and PSR-17 compatible request factory. If you would like to inject your own HTTP client or request factory, you can do so through the <code>httpClient</code> and <code>requestFactory</code> arguments.</p> <pre><code>&lt;?php\n$chain = new WebTextChain(\nhttpClient: new GuzzleHttp\\Client(),\nrequestFactory: new GuzzleHttp\\Psr7\\HttpFactory()\n);\n</code></pre>"},{"location":"reference/chains/standard-chains/webtext-chain/#changing-the-text-extractor","title":"Changing the text extractor","text":"<p>By default WebTextChain uses a <code>DOMDocument</code> based text extractor based on which strips a downloaded webpage from all its HTML and superfluous whitespace. If you would like to have WebTextChain use your own text extractor, you can simply implement the <code>Vexo\\Chain\\WebTextChain\\TextExtractor</code> interface and provide an instance of it through the <code>textExtractor</code> argument.</p> <pre><code>&lt;?php\nuse Vexo\\Chain\\WebTextChain\\TextExtractor;\n$textExtractor = new class() implements TextExtractor {\npublic function extract(string $contents): string {\nreturn strip_tags($contents);\n}\n};\n$chain = new WebTextChain(\ntextExtractor: $textExtractor\n);\n</code></pre>"},{"location":"reference/language-models/custom-models/","title":"Custom Language Models","text":"<p>The easiest way to create your own models is by extending the <code>Vexo\\LanguageModel\\BaseLanguageModel</code> class. This will implement the <code>Vexo\\LanguageModel\\LanguageModel</code> and <code>Vexo\\Event\\EventDispatcherAware</code> interfaces out of the box, and will make sure that the standard events are emitted. You will only have to implement a <code>call</code> method.</p> <p>You can do as follows.</p> <pre><code>&lt;?php\nuse Vexo\\LanguageModel\\BaseLanguageModel;\nuse Vexo\\LanguageModel\\Response;\nuse Vexo\\Prompt\\Prompt;\nfinal class AcmeLanguageModel extends BaseLanguageModel\n{\npublic function __construct(private AcmeClient $acmeClient)\n{\n}\nprotected function call(Prompt $prompt, string ...$stops): Response\n{\nreturn Response::fromString(\n(string) $this-&gt;acmeClient-&gt;complete((string) $prompt)\n);\n}\n}\n</code></pre> <p>Alternatively you can also instantiate and instance of <code>Vexo\\LanguageModel\\Response</code> yourself if you have additional metadata to pass on.</p> <pre><code>&lt;?php\nprotected function call(Prompt $prompt, string ...$stops): Response\n{\nreturn new Response(\nCompletions::fromString((string) $this-&gt;acmeClient-&gt;complete((string) $prompt)),\nnew ResponseMetadata(['tokenUsage' =&gt; $this-&gt;acmeClient-&gt;getTokenUsage()])\n);\n}\n</code></pre>"},{"location":"reference/language-models/custom-models/#emitting-events","title":"Emitting Events","text":"<p>The <code>BaseLanguageModel</code> class will emit the <code>StartedGeneratingCompletion</code> and <code>FinishedGeneratingCompletion</code> events on its own. If you would like to additionally emit your own events, you can use the <code>emit</code> method. Make sure your event implements <code>Vexo\\Event\\SomethingHappened</code>.</p> <pre><code>&lt;?php\nprotected function call(Prompt $prompt, string ...$stops): Response\n{\n// Some code...\n$this-&gt;emit(new AcmeEvent($prompt, $stops, 'Some other info'));\n// More code here...\n}\n</code></pre>"},{"location":"reference/language-models/events/","title":"Events","text":"<p>Models will emit the events outlined below. For more info on how to listen for events in Vexo, see Event Handling.</p>"},{"location":"reference/language-models/events/#emitted-events","title":"Emitted events","text":""},{"location":"reference/language-models/events/#vexolanguagemodelstartedgeneratingcompletion","title":"<code>Vexo\\LanguageModel\\StartedGeneratingCompletion</code>","text":"<p>Emitted just before the model will call upon the provide to generate a completion for a given prompt. Contains the following properties.</p> Property Description <code>Vexo\\Prompt\\Prompt $prompt</code> The prompt which was passed to the <code>generate</code> method. <code>string[] $stops</code> An array of stop words provided to the <code>generate</code> method, or an empty array."},{"location":"reference/language-models/events/#vexolanguagemodelfinishedgeneratingcompletion","title":"<code>Vexo\\LanguageModel\\FinishedGeneratingCompletion</code>","text":"<p>Emitted after the model has generated its completion for the given prompt, but before returning it to the caller.</p> Property Description <code>Vexo\\Prompt\\Prompt $prompt</code> The prompt which was passed to the <code>generate</code> method. <code>string[] $stops</code> An array of stop words provided to the <code>generate</code> method, or an empty array. <code>Vexo\\LanguageModel\\Response $response</code> The response object containing the generated completions and response metadata."},{"location":"reference/language-models/getting-started/","title":"Getting Started","text":"<p>Models in Vexo all implement the <code>Vexo\\LanguageModel\\LanguageModel</code> interface which provides a generic way to interact with language models.</p> <pre><code>&lt;?php\nLanguageModel::generate(Prompt $prompt, string ...$stops): Response\n</code></pre> <p>The <code>generate</code> method takes a prompt, and optionally one or more stop terms. It then produces a response containing the output of the language model and some additional metadata.</p> <p>Have a look at Providers to understand how to instantiate a new model of a particular provider. Once you have instantiated your model, you can simply use it as follows:</p> <pre><code>&lt;?php\n// Assumes $model is an instance of \\Vexo\\LanguageModel\\LanguageModel\n$response = $model-&gt;generate(\nnew \\Vexo\\Prompt('What is the capital of France?')\n);\n// Would contain the text response. E.g. \"The capital of France is Paris.\"\n$text = (string) $response-&gt;completions();\n</code></pre>"},{"location":"reference/language-models/getting-started/#1-creating-the-prompt","title":"1. Creating the Prompt","text":"<p>You can create a prompt by simply instantiating a new instance of <code>Prompt</code> as follows:</p> <pre><code>&lt;?php\n$prompt = new \\Vexo\\Prompt('What is the capital of France?');\n</code></pre>"},{"location":"reference/language-models/getting-started/#using-prompt-templates","title":"Using Prompt templates","text":"<p>Optionally, if you want to have a reusable prompt, you can also make use of a <code>PromptTemplate</code> and then construct the prompt when you're ready to call the model. To create the above prompt using a template instead, you can do the following:</p> <pre><code>&lt;?php\n$promptTemplate = new \\Vexo\\Prompt\\BasicPromptTemplate(\n'What is the capital of {{country}}?',\n['country']\n);\n$prompt = $promptTemplate-&gt;render(['country' =&gt; 'France']);\n</code></pre> <p>Currently Vexo only comes with the <code>BasicPromptTemplate</code>, but more may be added in the future.</p>"},{"location":"reference/language-models/getting-started/#2-calling-the-language-model","title":"2. Calling the Language Model","text":"<p>Once you have the prompt you can call the model to generate a response.</p> <pre><code>&lt;?php\n// $model is an instance of \\Vexo\\LanguageModel\\LanguageModel\n$response = $model-&gt;generate($prompt);\n</code></pre>"},{"location":"reference/language-models/getting-started/#using-stops","title":"Using stops","text":"<p>Optionally, if you want to make sure that the model stops generating as soon as it encounters particular tokens in its completion, you can provide them with the call. This is useful if your model tends to produce more output than is generally desired.</p> <p>For instance, if we only want a brief answer to our question above, but our model usually responds with something as follows:</p> <p>The capital of France is Paris. Paris is a beautiful city known for its stunning architecture, rich history, vibrant culture, world-class museums, and romantic atmosphere.</p> <p>We can force it to stop generating after the first sentence by providing <code>'. '</code> as a stop token.</p> <pre><code>&lt;?php\n$response = $model-&gt;generate($prompt, '. ');\n</code></pre> <p>The response will now simply contain the completion \"The capital of France is Paris.\"</p>"},{"location":"reference/language-models/getting-started/#3-interpreting-the-response","title":"3. Interpreting the Response","text":"<p>If you just want the text you can call the <code>completions</code> method on the response to return an instance of the <code>Vexo\\LanguageModel\\Completions</code> collection containing the generated text, which you can cast to a string.</p> <pre><code>&lt;?php\n$text = (string) $response-&gt;completions();\n</code></pre>"},{"location":"reference/language-models/getting-started/#multiple-completions","title":"Multiple completions","text":"<p>Some models are able to provide multiple alternate completions for the same prompt. The collection implements both PHP's <code>ArrayAccess</code> and <code>IteratorAggregate</code> for you to interact with the different completions should you need to.</p>"},{"location":"reference/language-models/getting-started/#response-metadata","title":"Response metadata","text":"<p>You can get additional metadata related to the response by calling the <code>metadata</code> method. The data returned is model-specific so you cannot assume its structure across different models.</p> <pre><code>&lt;?php\n$metadata = $response-&gt;metadata();\nprint_r($metadata-&gt;toArray());\n</code></pre> <p>The above would output something like this, depending on the model being used:</p> <pre><code>Array\n(\n  [model] =&gt; gpt-3.5-turbo\n  [usage] =&gt; Array\n    (\n      [prompt_tokens] =&gt; 9\n      [completion_tokens] =&gt; 12\n      [total_tokens] =&gt; 21\n    )\n)\n</code></pre>"},{"location":"reference/language-models/testing-with-models/","title":"Testing Models","text":"<p>Vexo provides a <code>Vexo\\LanguageModel\\FakeLanguageModel</code> which is a stub implementation of <code>Vexo\\LanguageModel\\LanguageModel</code>. You can use this for testing classes that depend on it.</p> <pre><code>&lt;?php\nuse Vexo\\LanguageModel\\FakeLanguageModel;\nuse Vexo\\LanguageModel\\Response;\n$model = new FakeLanguageModel([\nnew Response::fromString('The first response'),\nnew Response::fromString('The second response')\n]);\n$model-&gt;generate('A prompt'); // Returns the first response\n$model-&gt;generate('Another prompt'); // Returns the second response\n$model-&gt;generate('Prompt unaccounted for'); // Throws a LogicException\n</code></pre>"},{"location":"reference/language-models/available-models/","title":"Available Models","text":"<p>The following models are currently implemented by Vexo.</p> <ul> <li>OpenAI Chat - a wrapper around OpenAI's Chat API.</li> </ul>"},{"location":"reference/language-models/available-models/openai-chat/","title":"OpenAI Chat","text":"<p>Vexo provides a Language Model implementation around the OpenAI Chat API.</p>"},{"location":"reference/language-models/available-models/openai-chat/#prerequisites","title":"Prerequisites","text":"<p>You require an OpenAI account and API key to be able to use this model. You can create a key on your API keys page once you are logged in at OpenAI.</p>"},{"location":"reference/language-models/available-models/openai-chat/#instantiating","title":"Instantiating","text":"<p>You can instantiate the model as follows, using the default <code>gpt-3.5-turbo</code> OpenAI model.</p> <pre><code>&lt;?php\n// Replace this with your API key\n$apiKey = getenv('OPENAI_API_KEY');\n// Get a representation of the OpenAI Chat API\n$chatApi = OpenAI::client($apiKey)-&gt;chat();\n// Create the model\n$model = new Vexo\\LanguageModel\\OpenAIChatLanguageModel($chatApi);\n</code></pre>"},{"location":"reference/language-models/available-models/openai-chat/#additional-parameters","title":"Additional Parameters","text":"<p>If you want to override the model being used or provide other parameters, you can pass them along when instantiating your model.</p> <pre><code>&lt;?php\n$model = new Vexo\\LanguageModel\\OpenAIChatLanguageModel(\n$chatApi,\nnew Vexo\\LanguageModel\\Parameters([\n'model' =&gt; 'gpt-4',\n'temperature' =&gt; 0.8,\n'presence_penalty' =&gt; 0.5\n])\n);\n</code></pre> <p>For a full list of available parameters, please refer to the OpenAI API reference. Please note that the <code>stream</code> parameter is not supported at this time.</p>"},{"location":"reference/language-models/available-models/openai-chat/#prompt-prepending","title":"Prompt prepending","text":"<p>You can add default prompts as model parameters which will be prepended to all requests. This is useful when you want to add system prompts needed to guide the model, but you don't want to include them with every call to the model. </p> <pre><code>&lt;?php\n$model = new Vexo\\LanguageModel\\OpenAIChatLanguageModel(\n$chatApi,\nnew Vexo\\LanguageModel\\Parameters([\n'messages' =&gt; [\n['role' =&gt; 'system', 'content' =&gt; 'You are concise in all your responses']\n]\n])\n);\n</code></pre>"},{"location":"reference/prompts/simple-prompts/","title":"Simple Prompts","text":"<p>Prompts are input provided to models, which serve as a starting point or a cue for the model to generate a response in a particular manner.</p> <p>Prompts are usually constructed from different components to provide the model with instructions which are context-aware, and help the model respond in a format which can be easily parsed.</p> <p>Vexo provides a basic <code>Prompt</code> value object which you can use to wrap your prompt.</p> <pre><code>&lt;?php\n$prompt = new Vexo\\Prompt\\Prompt('What is the capital of France?');\n</code></pre> <p>Right now Vexo only supports text-based prompts. In the future this may be expanded to include other types of input like images.</p>"},{"location":"reference/prompts/templates/","title":"Templates","text":"<p>Prompt templates are used to construct prompts from a predefined format combined with relevant data.</p>"},{"location":"reference/prompts/templates/#basic-prompt-template","title":"Basic Prompt Template","text":"<p>Vexo provides <code>Vexo\\Prompt\\BasicPromptTemplate</code> which can be used to construct prompts using basic templates. You provide the template, and any placeholder names which are to be replaced when rendering the template.</p> <pre><code>&lt;?php\n$promptTemplate = new Vexo\\Prompt\\BasicPromptTemplate(\n'Act as a travel agent. Come up with a {{days}}-day itinerary for a trip to {{destination}}.',\n['days', 'destination']\n);\n</code></pre> <p>You can then render your prompt as follows:</p> <pre><code>&lt;?php\n$prompt = $promptTemplate-&gt;render(['days' =&gt; 3, 'destination' =&gt; 'Barcelona, Spain']);\n</code></pre> <p>This will render a prompt containing the following:</p> <pre><code>Act as a travel agent. Come up with a 3-day itinerary for a trip to Barcelona, Spain.\n</code></pre> <p>A <code>Vexo\\Prompt\\SorryNotAllRequiredValuesWereGiven</code> exception will be thrown if not all the specified placeholders are passed to the call to <code>render()</code>.</p>"}]}